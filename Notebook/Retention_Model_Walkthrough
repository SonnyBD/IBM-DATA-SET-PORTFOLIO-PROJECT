#%% md 
# üìä Predicting Employee Retention Risk 
 
This notebook walks through a complete machine learning pipeline to predict employee attrition risk using the IBM HR Analytics dataset. 
 
The goal is to support HR decision-making by identifying at-risk employees and explaining the factors contributing to their attrition risk using interpretable machine learning techniques. 
#%% md 
#%% md 
## 1. Load & Preview Data 
 
This dataset includes demographic, performance, and engagement-related features from IBM HR records. It provides the foundation for modeling employee attrition. 
#%% 
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.calibration import CalibratedClassifierCV
from sklearn.feature_selection import RFE
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns
import shap

# Load data
df = pd.read_excel('../data/IBM_Test_Project_Preprocessed_Data.xlsx')
df.head()
#%% md 
## 2. Feature Engineering 
 
We create composite features (e.g., an engagement index, promotion rate) that capture employee behavior and experience more effectively than raw columns alone. 
#%% 
# Create engineered features
if "JobSatisfaction" in df.columns and "WorkLifeBalance" in df.columns:
    df["Engagement_Index"] = df["JobSatisfaction"] * df["WorkLifeBalance"]
if "YearsSinceLastPromotion" in df.columns and "YearsAtCompany" in df.columns:
    df["Promotion_Rate"] = df["YearsSinceLastPromotion"] / (df["YearsAtCompany"] + 1)
if "Doing_Overtime" in df.columns and "Laboratory_Technician" in df.columns:
    df["Overtime_SensitiveRole"] = df["Doing_Overtime"] * df["Laboratory_Technician"]
#%% md 
## 3. Prepare Data 
 
We standardize continuous variables, remove identifiers, and separate features (X) from the target variable (`Retained`). 
#%% 
# Drop identifier and separate target
X = df.drop(columns=["Retained", "EmployeeNumber"], errors='ignore')
y = df["Retained"]

# Scale features
scaler_std = StandardScaler()
X_scaled = scaler_std.fit_transform(X)
#%% md 
## 4. Train/Test Split and SMOTE 
 
Attrition is rare (~16%), so we use SMOTE (Synthetic Minority Oversampling) to balance the classes and prevent bias toward predicting ‚Äúretained‚Äù employees. 
#%% 
# Split and balance
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
sm = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)
#%% md 
## 5. Feature Selection (RFE) 
 
We apply Recursive Feature Elimination (RFE) using a Random Forest base model to select the 20 most predictive features for modeling. 
#%% 
rfe_selector = RFE(estimator=RandomForestClassifier(), n_features_to_select=20)
rfe_selector.fit(X_scaled, y)
X_selected = X.loc[:, rfe_selector.support_]
X_scaled_selected = scaler_std.fit_transform(X_selected)
X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(X_scaled_selected, y, test_size=0.2, random_state=42)
X_train_sel_res, y_train_sel_res = sm.fit_resample(X_train_sel, y_train_sel)
#%% md 
## 6. Model Training & Calibration 
 
We use GridSearchCV to tune a Random Forest model and apply Platt scaling via sigmoid calibration to improve the quality of predicted probabilities. 
#%% 
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='f1', n_jobs=-1)
rf_grid.fit(X_train_sel_res, y_train_sel_res)
rf_model = rf_grid.best_estimator_

calibrated_rf = CalibratedClassifierCV(rf_model, method='sigmoid', cv=5)
calibrated_rf.fit(X_train_sel_res, y_train_sel_res)
#%% md 
## 7. Model Evaluation 
 
We assess the model using accuracy, precision, recall, F1-score, and confusion matrix. High recall is prioritized to reduce false negatives (i.e., missed attrition cases). 
#%% 
y_pred_rf = calibrated_rf.predict(X_test_sel)
print("Confusion Matrix:\n", confusion_matrix(y_test_sel, y_pred_rf))
print("Classification Report:\n", classification_report(y_test_sel, y_pred_rf))
print("Accuracy:", accuracy_score(y_test_sel, y_pred_rf))

cv_scores = cross_val_score(calibrated_rf, X_scaled_selected, y, cv=5, scoring='f1')
print("Cross-validated F1 scores:", cv_scores)
#%% md 
## 8. Generate Retention Risk Scores 
 
We convert predicted probabilities into retention risk scores using a Min-Max scaler and then assign each employee a risk level (Low, Moderate, High). 
#%% 
df["Predicted_Prob_Stay"] = calibrated_rf.predict_proba(X_scaled_selected)[:, 1]
scaler = MinMaxScaler()
df["Retention_Risk"] = 1 - scaler.fit_transform(df[["Predicted_Prob_Stay"]])

percentile_90 = df["Retention_Risk"].quantile(0.90)
percentile_50 = df["Retention_Risk"].quantile(0.50)

df["Risk_Level"] = pd.cut(df["Retention_Risk"], bins=[-float("inf"), percentile_50, percentile_90, float("inf")], labels=["Low Risk", "Moderate Risk", "High Risk"])
#%% md 
## 9. Export Results 
 
The final dataset is exported as an Excel file and includes employee retention probabilities, risk scores, and assigned risk tiers for HR stakeholders. 
#%% 
df_sorted = df.sort_values(by="Retention_Risk", ascending=False)
df_sorted.to_excel("../outputs/Retention_Risk_Analysis_Output.xlsx", index=False)
#%% 
#%% md 
## 10. SHAP Explainability 
 
We use SHAP values to interpret the model's predictions. This allows us to identify the top drivers of attrition and communicate model results transparently to HR teams. 
#%% 
explainer = shap.Explainer(rf_model, X_scaled_selected)
shap_values = explainer(X_scaled_selected, check_additivity=False)
shap.summary_plot(shap_values, X_selected, plot_type="bar")
#%% md 
## ‚úÖ Conclusion & Business Takeaways 
 
- The calibrated Random Forest model achieved **88% accuracy** and **98% recall** in identifying high-risk employees. 
- **Top predictors** of attrition included Overtime, Promotion Rate, and Job Satisfaction. 
- Employees were categorized into **Low**, **Moderate**, and **High Risk** tiers based on predicted probabilities. 
- **SHAP values** made the model transparent, enabling HR to understand and trust the predictions. 
 
This project demonstrates how People Analytics and interpretable machine learning can be leveraged to reduce turnover and drive strategic retention planning.
