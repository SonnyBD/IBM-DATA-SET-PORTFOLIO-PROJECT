{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a0e4c1",
   "metadata": {},
   "source": [
    #%% md
# ðŸ“Š Predicting Employee Retention Risk

This notebook walks through a complete machine learning pipeline to predict employee attrition risk using the IBM HR Analytics dataset.

The goal is to support HR decision-making by identifying at-risk employees and explaining the factors contributing to their attrition risk using interpretable machine learning techniques.
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccfffa",
   "metadata": {},
   "source": [
    "## 1. Load & Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('../data/IBM_Test_Project_Preprocessed_Data.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f6afd3",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4934a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engineered features\n",
    "if \"JobSatisfaction\" in df.columns and \"WorkLifeBalance\" in df.columns:\n",
    "    df[\"Engagement_Index\"] = df[\"JobSatisfaction\"] * df[\"WorkLifeBalance\"]\n",
    "if \"YearsSinceLastPromotion\" in df.columns and \"YearsAtCompany\" in df.columns:\n",
    "    df[\"Promotion_Rate\"] = df[\"YearsSinceLastPromotion\"] / (df[\"YearsAtCompany\"] + 1)\n",
    "if \"Doing_Overtime\" in df.columns and \"Laboratory_Technician\" in df.columns:\n",
    "    df[\"Overtime_SensitiveRole\"] = df[\"Doing_Overtime\"] * df[\"Laboratory_Technician\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc4035",
   "metadata": {},
   "source": [
    "## 3. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop identifier and separate target\n",
    "X = df.drop(columns=[\"Retained\", \"EmployeeNumber\"], errors='ignore')\n",
    "y = df[\"Retained\"]\n",
    "\n",
    "# Scale features\n",
    "scaler_std = StandardScaler()\n",
    "X_scaled = scaler_std.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e968aa",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42336f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317b1c5",
   "metadata": {},
   "source": [
    "## 5. Feature Selection (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af43cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_selector = RFE(estimator=RandomForestClassifier(), n_features_to_select=20)\n",
    "rfe_selector.fit(X_scaled, y)\n",
    "X_selected = X.loc[:, rfe_selector.support_]\n",
    "X_scaled_selected = scaler_std.fit_transform(X_selected)\n",
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(X_scaled_selected, y, test_size=0.2, random_state=42)\n",
    "X_train_sel_res, y_train_sel_res = sm.fit_resample(X_train_sel, y_train_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d27c56",
   "metadata": {},
   "source": [
    "## 6. Model Training & Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "rf_grid.fit(X_train_sel_res, y_train_sel_res)\n",
    "rf_model = rf_grid.best_estimator_\n",
    "\n",
    "calibrated_rf = CalibratedClassifierCV(rf_model, method='sigmoid', cv=5)\n",
    "calibrated_rf.fit(X_train_sel_res, y_train_sel_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5eac2",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d51272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = calibrated_rf.predict(X_test_sel)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_sel, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_sel, y_pred_rf))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_sel, y_pred_rf))\n",
    "\n",
    "cv_scores = cross_val_score(calibrated_rf, X_scaled_selected, y, cv=5, scoring='f1')\n",
    "print(\"Cross-validated F1 scores:\", cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cdb1c1",
   "metadata": {},
   "source": [
    "## 8. Generate Retention Risk Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Predicted_Prob_Stay\"] = calibrated_rf.predict_proba(X_scaled_selected)[:, 1]\n",
    "scaler = MinMaxScaler()\n",
    "df[\"Retention_Risk\"] = 1 - scaler.fit_transform(df[[\"Predicted_Prob_Stay\"]])\n",
    "\n",
    "percentile_90 = df[\"Retention_Risk\"].quantile(0.90)\n",
    "percentile_50 = df[\"Retention_Risk\"].quantile(0.50)\n",
    "\n",
    "df[\"Risk_Level\"] = pd.cut(df[\"Retention_Risk\"], bins=[-float(\"inf\"), percentile_50, percentile_90, float(\"inf\")], labels=[\"Low Risk\", \"Moderate Risk\", \"High Risk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d196d913",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df.sort_values(by=\"Retention_Risk\", ascending=False)\n",
    "df_sorted.to_excel(\"../outputs/Retention_Risk_Analysis_Output.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292ee45",
   "metadata": {},
   "source": [
    "## 10. SHAP Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf_model, X_scaled_selected)\n",
    "shap_values = explainer(X_scaled_selected, check_additivity=False)\n",
    "shap.summary_plot(shap_values, X_selected, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
